#' @title SERRF functions.
#' @description A QC based normalization method. Tidymass batch effect remove based on MS1 information of each batch, but SERRF didn't require MS1.
#' @references https://slfan2013.github.io/SERRF-online/
#' @author Shawn Wang
#' \email{shawnwang2016@126.com}
#' @param obj mass_dataset, An object mass_dataset from massdataset package
#' @param QC_tag character, QC lable in sample_info column 'class'.
#' @param cluster_num how may cores do you want to use
#' @param seed seed for serrf
#' @importFrom data.table as.data.table
#' @importFrom stats rnorm median sd
#' @importFrom ranger ranger
#' @importFrom tidyr pivot_longer
#' @importFrom grDevices boxplot.stats
#' @importFrom bootstrap crossval
#' @importFrom furrr future_map_dfc
#' @importFrom progressr progressor with_progress
#' @importFrom future plan
#' @importFrom magrittr %>%
#' @importFrom BiocGenerics intersect do.call
#' @importFrom dplyr mutate select
#' @importFrom crayon green bold italic red yellow
#' @return A SERRF normalized mass_dataset.
#' @export


run_serrf = function(obj,QC_tag,cluster_num = 8,seed = 2021) {
  msg_yes = green$bold$italic
  msg_no = red$bold$italic
  msg_warning = yellow$bold$italic
  if (class(obj) != "mass_dataset"){
    message(msg_no("error: please check the obj_old and obj_new, make sure they are mass_datasets which generated by massdataset package."))
    return()
  }
  # Parameters and imported data----
  p =
    obj@sample_info %>%
    dplyr::mutate(
      label = sample_id,
      time = injection.order,
      sampleType = case_when(
        class == QC_tag ~ "qc",
        TRUE ~ "sample"
      ))
  if('batch' %in% colnames(p)) {
    p =
      p %>%
      select(label,time,sampleType,batch) %>%
      as.data.table()
  } else {
    p =
      p %>%
      mutate(
        batch = "A"
      ) %>%
      select(label,time,sampleType,batch) %>%
      as.data.table()
  }
  expression_data = obj@expression_data %>% as.data.frame()
  e = as.matrix(expression_data)
  f = data.frame(
    label = rownames(expression_data),
    No = seq(1:nrow(expression_data))
  ) %>%
    as.data.table()

  # functions -----------------
  remove_outlier = function(v){
    out = boxplot.stats(v)$out
    return(list(value = v[!v%in%out],index = which(v%in%out)))
  } ## outlier remove
  RSD = function(data){
    return(apply(data,1,function(x){
      x = remove_outlier(x)[[1]]
      return(sd(x,na.rm=T)/mean(x,na.rm=T))
    }))
  }## calculate RSD
  # make blank lists.
  qc_RSDs = list()
  normalized_dataset = list()
  calculation_times = list()
  with_validate = any(!p$sampleType %in% c('qc','sample'))
  # split e, and p to different sample type.
  e_qc = e[, p$sampleType == 'qc']
  e_sample = e[, p$sampleType == 'sample']
  p_qc = p[p$sampleType == 'qc',]
  p_sample = p[p$sampleType == 'sample',]
  e_validates = list()
  p_validates = list()
  validate_types = NULL
  aggregate_e = function(e_qc,e_sample,e_validates){
    e = BiocGenerics::do.call('cbind',c(list(e_qc, e_sample), e_validates))
    e = e[,order(as.numeric(gsub("p","",colnames(e))))]
    return(e)
  }

  # Start -------------------------
  start = Sys.time()
  normalized_dataset[['none']] = aggregate_e(e_qc,e_sample,e_validates)
  qc_RSDs[['none']] = RSD(e_qc)
  calculation_times[['none']] = Sys.time() - start
  message(msg_yes("<!--------- raw data --------->\n"))
  message(msg_warning(paste0("Average QC RSD:",signif(median(qc_RSDs[['none']],na.rm = TRUE),4)*100,"%.\n")))
  message(msg_warning(paste0("Number of compounds less than 20% QC RSD:",sum(qc_RSDs[['none']]<0.2,na.rm = TRUE),".\n")))
  normalized_dataset[['SERRF']] = tryCatch({
    set.seed(seed = seed)
    message(msg_yes("<!--------- SERRF --------->\n(This may take a while...)\n"))
    e_norm = matrix(,nrow=nrow(e),ncol=ncol(e))
    QC.index = p[["sampleType"]]
    batch = p[["batch"]]
    time = p[["time"]]
    batch = factor(batch)
    num = 10
    start = Sys.time();
    # setting used cores
    cl = makeCluster(cluster_num)
    ## functions
    serrfR = function(train = e[,p$sampleType == 'qc'], ## set qc samples as train matrix
                      target = e[,p$sampleType == 'sample'], ## set samples as target matrix
                      num = 10,
                      batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),
                      time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),
                      sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl){
      all = cbind(train, target)
      normalized = rep(0, ncol(all))

      # Missing value imputation via batch.

      for(j in 1:nrow(all)){
        for(b in 1:length(unique(batch.))){
          current_batch = levels(batch.)[b]
          ## Imputation of value equals 0
          all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0] =
            stats::rnorm(
              length(all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0]),
              mean = min(all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])+1,
              sd = 0.1*(min(all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])+.1)
            )
          ## Imputation of NA value.
          all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])] =
            stats::rnorm(
              length(all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])]),
              mean = 0.5*min(all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])+1,
              sd = 0.1*(min(all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])+.1)
            )
        }
      }

      ## corrlation of train sets and target sets.

      corrs_train = list()
      corrs_target = list()
      for(b in 1:length(unique(batch.))){

        current_batch = levels(batch.)[b]

        train_scale = t(apply(train[,batch.[sampleType.=='qc']%in%current_batch],1,scale))
        if(is.null(target[,batch.[!sampleType.=='qc']%in%current_batch])){
          target_scale = t(apply(target[,batch.[!sampleType.=='qc']%in%current_batch],1,scale))
        }else{
          target_scale = scale(target[,batch.[!sampleType.=='qc']%in%current_batch])
        }

        corrs_train[[current_batch]] = cor(t(train_scale), method = "spearman")
        corrs_target[[current_batch]] = cor(t(target_scale), method = "spearman")
      }

      get_pred = function(.x) {
        j  = .x
        normalized  = rep(0, ncol(all))
        qc_train_value = list()
        qc_predict_value = list()
        sample_value = list()
        sample_predict_value = list()

        for(b in 1:length(levels(batch.))){
          current_batch = levels(batch.)[b]
          e_current_batch = all[,batch.%in%current_batch]
          corr_train = corrs_train[[current_batch]]
          corr_target = corrs_target[[current_batch]]
          corr_train_order = order(abs(corr_train[,j]),decreasing = TRUE)
          corr_target_order = order(abs(corr_target[,j]),decreasing = TRUE)
          sel_var = c()
          l = num
          while(length(sel_var)<(num)){
            sel_var = intersect(corr_train_order[1:l], corr_target_order[1:l])
            sel_var = sel_var[!sel_var == j]
            l = l+1
          }
          train.index_current_batch = sampleType.[batch.%in%current_batch]
          train_data_y = scale(e_current_batch[j, train.index_current_batch=='qc'],scale=F)
          train_data_x = apply(e_current_batch[sel_var, train.index_current_batch=='qc'],1,scale)

          if(is.null(dim(e_current_batch[sel_var, !train.index_current_batch=='qc']))){
            test_data_x = t(scale(e_current_batch[sel_var, !train.index_current_batch=='qc']))
          }else{
            test_data_x = apply(e_current_batch[sel_var, !train.index_current_batch=='qc'],1,scale)
          }

          train_NA_index  = apply(train_data_x,2,function(x){
            sum(is.na(x))>0
          })

          train_data_x = train_data_x[,!train_NA_index]
          test_data_x = test_data_x[,!train_NA_index]

          if(!"matrix"%in%class(test_data_x)){
            test_data_x = t(test_data_x)
          }

          good_column = apply(train_data_x,2,function(x){sum(is.na(x))==0}) & apply(test_data_x,2,function(x){sum(is.na(x))==0})
          train_data_x = train_data_x[,good_column]
          test_data_x = test_data_x[,good_column]
          if(!"matrix"%in%class(test_data_x)){
            test_data_x = t(test_data_x)
          }
          train_data = data.frame(y = train_data_y,train_data_x )

          if(ncol(train_data)==1){# some samples have all QC constent.
            norm = e_current_batch[j,]
            normalized[batch.%in%current_batch] = norm
          }else{
            colnames(train_data) = c("y", paste0("V",1:(ncol(train_data)-1)))
            model = ranger::ranger(y~., data = train_data)

            test_data = data.frame(test_data_x)
            colnames(test_data) = colnames(train_data)[-1]
            norm = e_current_batch[j,]
            norm[train.index_current_batch=='qc'] = e_current_batch[j, train.index_current_batch=='qc']/((predict(model, data = train_data)$prediction+mean(e_current_batch[j,train.index_current_batch=='qc'],na.rm=TRUE))/mean(all[j,sampleType.=='qc'],na.rm=TRUE))
            norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))/(median(all[j,!sampleType.=='qc'],na.rm = TRUE)))
            norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
            norm[train.index_current_batch=='qc'] = norm[train.index_current_batch=='qc']/(median(norm[train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,sampleType.=='qc'],na.rm=TRUE))
            norm[!train.index_current_batch=='qc'] = norm[!train.index_current_batch=='qc']/(median(norm[!train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,!sampleType.=='qc'],na.rm=TRUE))
            set.seed(seed = seed)
            norm[!is.finite(norm)] = rnorm(length(norm[!is.finite(norm)]),sd = sd(norm[is.finite(norm)],na.rm=TRUE)*0.01)
            out = boxplot.stats(norm, coef = 3)$out
            norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']%in%out] = ((e_current_batch[j,!train.index_current_batch=='qc'])-((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))-(median(all[j,!sampleType.=='qc'],na.rm = TRUE))))[norm[!train.index_current_batch=='qc']%in%out];
            norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
            normalized[batch.%in%current_batch] = norm
          }
        }
        df = data.frame(.x = normalized) %>% setNames(.x)
        return(df)
      }

      get_pred_progress <- function(all) {
        p <- progressr::progressor(steps = nrow(all));
        b = furrr::future_map_dfc(.x = 1:nrow(all),.f = function(.x) {
          p()
          a = get_pred(.x)
          return(a)
        })
        return(b)
      }
      future::plan("multisession",workers = cluster_num )
      with_progress({
        pred = get_pred_progress(all)
      })
      names(pred) = c(1:ncol(pred))
      normed = t(pred)
      normed_target = normed[,!sampleType.=='qc']
      for(i in 1:nrow(normed_target)){
        normed_target[i,is.na(normed_target[i,])] = rnorm(sum(is.na(normed_target[i,])), mean = min(normed_target[i,!is.na(normed_target[i,])], na.rm = TRUE), sd = sd(normed_target[i,!is.na(normed_target[i,])])*0.1)
      }
      for(i in 1:nrow(normed_target)){
        normed_target[i,normed_target[i,]<0] = runif(1) * min(normed_target[i,normed_target[i,]>0], na.rm = TRUE)
      }
      normed_train = normed[,sampleType.=='qc']
      for(i in 1:nrow(normed_train)){
        normed_train[i,is.na(normed_train[i,])] = rnorm(sum(is.na(normed_train[i,])), mean = min(normed_train[i,!is.na(normed_train[i,])], na.rm = TRUE), sd = sd(normed_train[i,!is.na(normed_train[i,])])*0.1)
      }
      for(i in 1:nrow(normed_train)){
        normed_train[i,normed_train[i,]<0] = runif(1) * min(normed_train[i,normed_train[i,]>0], na.rm = TRUE)
      }
      return(list(normed_train=normed_train,normed_target=normed_target))
    }
    serrf_normalized = e
    serrf_normalized_modeled = serrfR(train = e_qc, target = e_sample, num = num,batch. = factor(c(p_qc$batch, p_sample$batch)),time. = c(p_qc$time, p_sample$time),sampleType. = c(p_qc$sampleType, p_sample$sampleType),cl)

    serrf_qc = serrf_normalized_modeled$normed_train
    colnames(serrf_qc) = colnames(e_qc)
    serrf_sample = serrf_normalized_modeled$normed_target
    colnames(serrf_sample) = colnames(e_sample)

    serrf_cross_validated_qc = e_qc

    cv = 5
    RSDs = list()
    if(any(table(p_qc$batch))<7){
      ratio = 0.7
    }else{
      ratio = 0.8
    }

    test_indexes = split(1L:nrow(p_qc), c(1L:nrow(p_qc))%%cv)

    for(k in 1:cv){

      test_index = test_indexes[[k]]
      train_index = c(1L:nrow(p_qc))[-test_index]

      train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
      test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]


      while(length(unique(p_qc$batch[test_index]))<length(unique(batch))){
        train_index = sample(1L:nrow(p_qc),round(nrow(p_qc)*ratio))
        test_index = c(1L:nrow(p_qc))[!(c(1L:nrow(p_qc))%in%train_index)]
      }
      serrf_normalized_on_cross_validate = serrfR(train = e_qc[,train_index], target = e_qc[,test_index], num = num,batch. = factor(c(p_qc$batch[train_index],p_qc$batch[test_index])),time. = c(p_qc$time[train_index],p_qc$time[test_index]),sampleType. = rep(c("qc","sample"),c(length(train_index),length(test_index))),cl)

      serrf_cross_validated_qc[,test_index] = serrf_normalized_on_cross_validate$normed_target

      RSDs[[k]] = RSD(serrf_normalized_on_cross_validate$normed_target)
    }
    qc_RSD = apply(do.call("cbind",RSDs),1,mean)
    qc_RSDs[['SERRF']] = qc_RSD
    calculation_times[['SERRF']] = Sys.time() - start
    message(msg_warning(paste0("Average QC RSD:",signif(median(qc_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n")))
    message(msg_warning(paste0("Number of compounds less than 20% QC RSD:",sum(qc_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n")))


    serrf_validates = list()
    if(with_validate){


      for(validate_type in validate_types){

        serrf_validates[[validate_type]] = serrfR(train = e_qc, target = e_validates[[validate_type]], num = num,batch. = factor(c(p_qc$batch, p_validates[[validate_type]]$batch)),time. = c(p_qc$time, p_validates[[validate_type]]$time),sampleType. = rep(c("qc","sample"),c(nrow(p_qc),nrow(p_validates[[validate_type]]))),cl)$normed_target

        colnames(serrf_validates[[validate_type]]) = colnames(e_validates[[validate_type]])

        val_RSDs[[validate_type]][['SERRF']] = RSD(serrf_validates[[validate_type]])
        message(msg_warning(paste0("Average ",validate_type," RSD:",signif(median( val_RSDs[[validate_type]][['SERRF']],na.rm = TRUE),4)*100,"%.\n")))
        message(msg_warning(paste0("Number of compounds less than 20% ",validate_type," RSD:",sum( val_RSDs[[validate_type]][['SERRF']]<0.2,na.rm = TRUE),".\n")))
      }
      aggregate_e(serrf_qc,serrf_sample,serrf_validates)
    }else{
      aggregate_e(serrf_qc,serrf_sample,NULL)
    }
  }, error = function(error_message){
    msg_no("something wrong with serrf check your input")
  })
  rownames(normalized_dataset[['SERRF']]) = rownames(normalized_dataset[['none']])
  #return(normalized_dataset)
  obj@expression_data = as.data.frame(normalized_dataset[['SERRF']])
  message(msg_yes("<!--------- SERRF --------->\n(All task finished...)\n"))
  return(obj)
}
